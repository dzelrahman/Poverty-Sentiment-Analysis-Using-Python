{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Cleaned Poverty Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>uncleaned_len</th>\n",
       "      <th>cleaned_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-09-30 19:39</td>\n",
       "      <td>Growing Food and Faith in Impoverished Brazil...</td>\n",
       "      <td>247</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-09-30 19:37</td>\n",
       "      <td>In yrs Vietnam from poverty to an emerging ma...</td>\n",
       "      <td>429</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-09-30 19:37</td>\n",
       "      <td>The Politics of Poverty Officials grapple wit...</td>\n",
       "      <td>309</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-09-30 19:29</td>\n",
       "      <td>Not just talking doing kenyalendahand kenya n...</td>\n",
       "      <td>292</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-09-30 19:24</td>\n",
       "      <td>Raiders Poverty</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              Date  \\\n",
       "0           1  2018-09-30 19:39   \n",
       "1           2  2018-09-30 19:37   \n",
       "2           3  2018-09-30 19:37   \n",
       "3           4  2018-09-30 19:29   \n",
       "4           5  2018-09-30 19:24   \n",
       "\n",
       "                                              Tweets  uncleaned_len  \\\n",
       "0   Growing Food and Faith in Impoverished Brazil...            247   \n",
       "1   In yrs Vietnam from poverty to an emerging ma...            429   \n",
       "2   The Politics of Poverty Officials grapple wit...            309   \n",
       "3   Not just talking doing kenyalendahand kenya n...            292   \n",
       "4                                   Raiders Poverty              25   \n",
       "\n",
       "   cleaned_len  \n",
       "0           89  \n",
       "1          220  \n",
       "2           96  \n",
       "3          166  \n",
       "4           17  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"CleanedPovertyTweets_v1.csv\")\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all tweets to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     growing food and faith in impoverished brazil...\n",
       "1     in yrs vietnam from poverty to an emerging ma...\n",
       "2     the politics of poverty officials grapple wit...\n",
       "3     not just talking doing kenyalendahand kenya n...\n",
       "4                                     raiders poverty \n",
       "5     for all those who believe the world has gone ...\n",
       "6     even breathing is a risk in one of orlando s ...\n",
       "7     maybe it s time to rethink the idea that we k...\n",
       "8     this is why i volunteer with big bros big sis...\n",
       "9     americas children in brief key national indic...\n",
       "Name: Tweets, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Tweets'] = train['Tweets'].apply(lambda x: x.lower())\n",
    "train.Tweets.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop Words Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Nugrahan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "train['Tweets'] = train['Tweets'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>uncleaned_len</th>\n",
       "      <th>cleaned_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-09-30 19:39</td>\n",
       "      <td>growing food faith impoverished brazil ben dem...</td>\n",
       "      <td>247</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-09-30 19:37</td>\n",
       "      <td>yrs vietnam poverty emerging market ans oi moi...</td>\n",
       "      <td>429</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-09-30 19:37</td>\n",
       "      <td>politics poverty officials grapple works doesn...</td>\n",
       "      <td>309</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-09-30 19:29</td>\n",
       "      <td>talking kenyalendahand kenya nairobi kibera ja...</td>\n",
       "      <td>292</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-09-30 19:24</td>\n",
       "      <td>raiders poverty</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              Date  \\\n",
       "0           1  2018-09-30 19:39   \n",
       "1           2  2018-09-30 19:37   \n",
       "2           3  2018-09-30 19:37   \n",
       "3           4  2018-09-30 19:29   \n",
       "4           5  2018-09-30 19:24   \n",
       "\n",
       "                                              Tweets  uncleaned_len  \\\n",
       "0  growing food faith impoverished brazil ben dem...            247   \n",
       "1  yrs vietnam poverty emerging market ans oi moi...            429   \n",
       "2  politics poverty officials grapple works doesn...            309   \n",
       "3  talking kenyalendahand kenya nairobi kibera ja...            292   \n",
       "4                                    raiders poverty             25   \n",
       "\n",
       "   cleaned_len  \n",
       "0           89  \n",
       "1          220  \n",
       "2           96  \n",
       "3          166  \n",
       "4           17  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spell Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Tweets.apply(lambda x: TextBlob(x).correct);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Nugrahan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "train['Tokensize']= train.Tweets.apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>uncleaned_len</th>\n",
       "      <th>cleaned_len</th>\n",
       "      <th>Tokensize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-09-30 19:39</td>\n",
       "      <td>growing food faith impoverished brazil ben dem...</td>\n",
       "      <td>247</td>\n",
       "      <td>89</td>\n",
       "      <td>[growing, food, faith, impoverished, brazil, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-09-30 19:37</td>\n",
       "      <td>yrs vietnam poverty emerging market ans oi moi...</td>\n",
       "      <td>429</td>\n",
       "      <td>220</td>\n",
       "      <td>[yrs, vietnam, poverty, emerging, market, ans,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-09-30 19:37</td>\n",
       "      <td>politics poverty officials grapple works doesn...</td>\n",
       "      <td>309</td>\n",
       "      <td>96</td>\n",
       "      <td>[politics, poverty, officials, grapple, works,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-09-30 19:29</td>\n",
       "      <td>talking kenyalendahand kenya nairobi kibera ja...</td>\n",
       "      <td>292</td>\n",
       "      <td>166</td>\n",
       "      <td>[talking, kenyalendahand, kenya, nairobi, kibe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-09-30 19:24</td>\n",
       "      <td>raiders poverty</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>[raiders, poverty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-09-30 19:23</td>\n",
       "      <td>believe world gone bonkers need evolve better ...</td>\n",
       "      <td>234</td>\n",
       "      <td>212</td>\n",
       "      <td>[believe, world, gone, bonkers, need, evolve, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2018-09-30 19:13</td>\n",
       "      <td>even breathing risk one orlando poorest neighb...</td>\n",
       "      <td>207</td>\n",
       "      <td>151</td>\n",
       "      <td>[even, breathing, risk, one, orlando, poorest,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2018-09-30 19:09</td>\n",
       "      <td>maybe time rethink idea know better people nee...</td>\n",
       "      <td>192</td>\n",
       "      <td>125</td>\n",
       "      <td>[maybe, time, rethink, idea, know, better, peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-09-30 19:00</td>\n",
       "      <td>volunteer big bros big sisters many american k...</td>\n",
       "      <td>191</td>\n",
       "      <td>166</td>\n",
       "      <td>[volunteer, big, bros, big, sisters, many, ame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>2018-09-30 19:00</td>\n",
       "      <td>americas children brief key national indicator...</td>\n",
       "      <td>279</td>\n",
       "      <td>211</td>\n",
       "      <td>[americas, children, brief, key, national, ind...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              Date  \\\n",
       "0           1  2018-09-30 19:39   \n",
       "1           2  2018-09-30 19:37   \n",
       "2           3  2018-09-30 19:37   \n",
       "3           4  2018-09-30 19:29   \n",
       "4           5  2018-09-30 19:24   \n",
       "5           6  2018-09-30 19:23   \n",
       "6           7  2018-09-30 19:13   \n",
       "7           8  2018-09-30 19:09   \n",
       "8           9  2018-09-30 19:00   \n",
       "9          10  2018-09-30 19:00   \n",
       "\n",
       "                                              Tweets  uncleaned_len  \\\n",
       "0  growing food faith impoverished brazil ben dem...            247   \n",
       "1  yrs vietnam poverty emerging market ans oi moi...            429   \n",
       "2  politics poverty officials grapple works doesn...            309   \n",
       "3  talking kenyalendahand kenya nairobi kibera ja...            292   \n",
       "4                                    raiders poverty             25   \n",
       "5  believe world gone bonkers need evolve better ...            234   \n",
       "6  even breathing risk one orlando poorest neighb...            207   \n",
       "7  maybe time rethink idea know better people nee...            192   \n",
       "8  volunteer big bros big sisters many american k...            191   \n",
       "9  americas children brief key national indicator...            279   \n",
       "\n",
       "   cleaned_len                                          Tokensize  \n",
       "0           89  [growing, food, faith, impoverished, brazil, b...  \n",
       "1          220  [yrs, vietnam, poverty, emerging, market, ans,...  \n",
       "2           96  [politics, poverty, officials, grapple, works,...  \n",
       "3          166  [talking, kenyalendahand, kenya, nairobi, kibe...  \n",
       "4           17                                 [raiders, poverty]  \n",
       "5          212  [believe, world, gone, bonkers, need, evolve, ...  \n",
       "6          151  [even, breathing, risk, one, orlando, poorest,...  \n",
       "7          125  [maybe, time, rethink, idea, know, better, peo...  \n",
       "8          166  [volunteer, big, bros, big, sisters, many, ame...  \n",
       "9          211  [americas, children, brief, key, national, ind...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pos Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/Nugrahan/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "train['POS_TAG'] = train['Tokensize'].apply(lambda x: pos_tag(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>POS_TAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>growing food faith impoverished brazil ben dem...</td>\n",
       "      <td>[(growing, VBG), (food, NN), (faith, NN), (imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>yrs vietnam poverty emerging market ans oi moi...</td>\n",
       "      <td>[(yrs, NN), (vietnam, NNP), (poverty, NN), (em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>politics poverty officials grapple works doesn...</td>\n",
       "      <td>[(politics, NNS), (poverty, NN), (officials, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>talking kenyalendahand kenya nairobi kibera ja...</td>\n",
       "      <td>[(talking, VBG), (kenyalendahand, NN), (kenya,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>raiders poverty</td>\n",
       "      <td>[(raiders, NNS), (poverty, VBP)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>believe world gone bonkers need evolve better ...</td>\n",
       "      <td>[(believe, JJ), (world, NN), (gone, VBN), (bon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>even breathing risk one orlando poorest neighb...</td>\n",
       "      <td>[(even, RB), (breathing, VBG), (risk, NN), (on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>maybe time rethink idea know better people nee...</td>\n",
       "      <td>[(maybe, RB), (time, NN), (rethink, VB), (idea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>volunteer big bros big sisters many american k...</td>\n",
       "      <td>[(volunteer, NN), (big, JJ), (bros, NN), (big,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>americas children brief key national indicator...</td>\n",
       "      <td>[(americas, JJ), (children, NNS), (brief, JJ),...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  \\\n",
       "0  growing food faith impoverished brazil ben dem...   \n",
       "1  yrs vietnam poverty emerging market ans oi moi...   \n",
       "2  politics poverty officials grapple works doesn...   \n",
       "3  talking kenyalendahand kenya nairobi kibera ja...   \n",
       "4                                    raiders poverty   \n",
       "5  believe world gone bonkers need evolve better ...   \n",
       "6  even breathing risk one orlando poorest neighb...   \n",
       "7  maybe time rethink idea know better people nee...   \n",
       "8  volunteer big bros big sisters many american k...   \n",
       "9  americas children brief key national indicator...   \n",
       "\n",
       "                                             POS_TAG  \n",
       "0  [(growing, VBG), (food, NN), (faith, NN), (imp...  \n",
       "1  [(yrs, NN), (vietnam, NNP), (poverty, NN), (em...  \n",
       "2  [(politics, NNS), (poverty, NN), (officials, N...  \n",
       "3  [(talking, VBG), (kenyalendahand, NN), (kenya,...  \n",
       "4                   [(raiders, NNS), (poverty, VBP)]  \n",
       "5  [(believe, JJ), (world, NN), (gone, VBN), (bon...  \n",
       "6  [(even, RB), (breathing, VBG), (risk, NN), (on...  \n",
       "7  [(maybe, RB), (time, NN), (rethink, VB), (idea...  \n",
       "8  [(volunteer, NN), (big, JJ), (bros, NN), (big,...  \n",
       "9  [(americas, JJ), (children, NNS), (brief, JJ),...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['Tweets', 'POS_TAG']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmetization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/Nugrahan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/KT12/tag-lemmatize/blob/master/tag-lemmatize.py\n",
    "\n",
    "#penn to wordnet, takes care of only 5 POS, rest converted to noun \n",
    "\n",
    "part = {\n",
    "    'N' : 'n',\n",
    "    'V' : 'v',\n",
    "    'J' : 'a',\n",
    "    'S' : 's',\n",
    "    'R' : 'r'\n",
    "}\n",
    "\n",
    "def convert_tag(penn_tag):\n",
    "    '''\n",
    "    convert_tag() accepts the **first letter** of a Penn part-of-speech tag,\n",
    "    then uses a dict lookup to convert it to the appropriate WordNet tag.\n",
    "    '''\n",
    "    if penn_tag in part.keys():\n",
    "        return part[penn_tag]\n",
    "    else:\n",
    "        # other parts of speech will be tagged as nouns\n",
    "        return 'n'\n",
    "    \n",
    "\n",
    "def tag_and_lem():\n",
    "    '''\n",
    "    tag_and_lem() accepts a string, tokenizes, tags, converts tags,\n",
    "    lemmatizes, and returns a string\n",
    "    '''\n",
    "    \"\"\n",
    "    \n",
    "\n",
    "    \n",
    "    lemm = []\n",
    "    i = 0\n",
    "    #sent = pos_tag(word_tokenize(element)) # must tag in context\n",
    "    for tweet in train.POS_TAG:\n",
    "        lemm = []\n",
    "        for words in tweet:\n",
    "            text = words[0]\n",
    "            tag = words[1]\n",
    "            lemm.append(\"\".join(lemmatiser.lemmatize(text, pos = convert_tag(tag))))\n",
    "        train.at[i, \"Lemmas\"] = lemm\n",
    "        i+= 1\n",
    "\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "train.insert(train.shape[1], 'Lemmas', '0')   #use this to create a default column \n",
    "lemmatiser = WordNetLemmatizer()\n",
    "tag_and_lem()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display Tweets after NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>uncleaned_len</th>\n",
       "      <th>cleaned_len</th>\n",
       "      <th>Tokensize</th>\n",
       "      <th>POS_TAG</th>\n",
       "      <th>Lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-09-30 19:39</td>\n",
       "      <td>growing food faith impoverished brazil ben dem...</td>\n",
       "      <td>247</td>\n",
       "      <td>89</td>\n",
       "      <td>[growing, food, faith, impoverished, brazil, b...</td>\n",
       "      <td>[(growing, VBG), (food, NN), (faith, NN), (imp...</td>\n",
       "      <td>[growing, food, faith, impoverished, brazil, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-09-30 19:37</td>\n",
       "      <td>yrs vietnam poverty emerging market ans oi moi...</td>\n",
       "      <td>429</td>\n",
       "      <td>220</td>\n",
       "      <td>[yrs, vietnam, poverty, emerging, market, ans,...</td>\n",
       "      <td>[(yrs, NN), (vietnam, NNP), (poverty, NN), (em...</td>\n",
       "      <td>[yr, vietnam, poverty, emerging, market, an, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-09-30 19:37</td>\n",
       "      <td>politics poverty officials grapple works doesn...</td>\n",
       "      <td>309</td>\n",
       "      <td>96</td>\n",
       "      <td>[politics, poverty, officials, grapple, works,...</td>\n",
       "      <td>[(politics, NNS), (poverty, NN), (officials, N...</td>\n",
       "      <td>[politics, poverty, official, grapple, work, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-09-30 19:29</td>\n",
       "      <td>talking kenyalendahand kenya nairobi kibera ja...</td>\n",
       "      <td>292</td>\n",
       "      <td>166</td>\n",
       "      <td>[talking, kenyalendahand, kenya, nairobi, kibe...</td>\n",
       "      <td>[(talking, VBG), (kenyalendahand, NN), (kenya,...</td>\n",
       "      <td>[talking, kenyalendahand, kenya, nairobi, kibe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-09-30 19:24</td>\n",
       "      <td>raiders poverty</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>[raiders, poverty]</td>\n",
       "      <td>[(raiders, NNS), (poverty, VBP)]</td>\n",
       "      <td>[raider, poverty]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              Date  \\\n",
       "0           1  2018-09-30 19:39   \n",
       "1           2  2018-09-30 19:37   \n",
       "2           3  2018-09-30 19:37   \n",
       "3           4  2018-09-30 19:29   \n",
       "4           5  2018-09-30 19:24   \n",
       "\n",
       "                                              Tweets  uncleaned_len  \\\n",
       "0  growing food faith impoverished brazil ben dem...            247   \n",
       "1  yrs vietnam poverty emerging market ans oi moi...            429   \n",
       "2  politics poverty officials grapple works doesn...            309   \n",
       "3  talking kenyalendahand kenya nairobi kibera ja...            292   \n",
       "4                                    raiders poverty             25   \n",
       "\n",
       "   cleaned_len                                          Tokensize  \\\n",
       "0           89  [growing, food, faith, impoverished, brazil, b...   \n",
       "1          220  [yrs, vietnam, poverty, emerging, market, ans,...   \n",
       "2           96  [politics, poverty, officials, grapple, works,...   \n",
       "3          166  [talking, kenyalendahand, kenya, nairobi, kibe...   \n",
       "4           17                                 [raiders, poverty]   \n",
       "\n",
       "                                             POS_TAG  \\\n",
       "0  [(growing, VBG), (food, NN), (faith, NN), (imp...   \n",
       "1  [(yrs, NN), (vietnam, NNP), (poverty, NN), (em...   \n",
       "2  [(politics, NNS), (poverty, NN), (officials, N...   \n",
       "3  [(talking, VBG), (kenyalendahand, NN), (kenya,...   \n",
       "4                   [(raiders, NNS), (poverty, VBP)]   \n",
       "\n",
       "                                              Lemmas  \n",
       "0  [growing, food, faith, impoverished, brazil, b...  \n",
       "1  [yr, vietnam, poverty, emerging, market, an, o...  \n",
       "2  [politics, poverty, official, grapple, work, d...  \n",
       "3  [talking, kenyalendahand, kenya, nairobi, kibe...  \n",
       "4                                  [raider, poverty]  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentimental analysis based on compund score of VADER\n",
    "sentiment = []\n",
    "i= 0 \n",
    "for tweet in train.Tweets:\n",
    "    vs = analyser.polarity_scores(tweet)\n",
    "    if vs['compound'] >= 0.5:\n",
    "        sentiment.append(1)\n",
    "    elif vs['compound'] <= -0.5:\n",
    "        sentiment.append(-1)\n",
    "    elif vs['compound'] > - 0.5 and vs['compound'] < 0.5:\n",
    "        sentiment.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtrain = pd.DataFrame(columns = ['Date', 'Review', 'Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new dataframe for storing sentiments values\n",
    "newtrain['Date'] = train.Date\n",
    "newtrain['Review'] = train.Tweets\n",
    "newtrain['Sentiment'] = sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018-09-30 19:39</td>\n",
       "      <td>growing food faith impoverished brazil ben dem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018-09-30 19:37</td>\n",
       "      <td>yrs vietnam poverty emerging market ans oi moi...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018-09-30 19:37</td>\n",
       "      <td>politics poverty officials grapple works doesn...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018-09-30 19:29</td>\n",
       "      <td>talking kenyalendahand kenya nairobi kibera ja...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018-09-30 19:24</td>\n",
       "      <td>raiders poverty</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2018-09-30 19:23</td>\n",
       "      <td>believe world gone bonkers need evolve better ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2018-09-30 19:13</td>\n",
       "      <td>even breathing risk one orlando poorest neighb...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2018-09-30 19:09</td>\n",
       "      <td>maybe time rethink idea know better people nee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2018-09-30 19:00</td>\n",
       "      <td>volunteer big bros big sisters many american k...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2018-09-30 19:00</td>\n",
       "      <td>americas children brief key national indicator...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date                                             Review  \\\n",
       "0  2018-09-30 19:39  growing food faith impoverished brazil ben dem...   \n",
       "1  2018-09-30 19:37  yrs vietnam poverty emerging market ans oi moi...   \n",
       "2  2018-09-30 19:37  politics poverty officials grapple works doesn...   \n",
       "3  2018-09-30 19:29  talking kenyalendahand kenya nairobi kibera ja...   \n",
       "4  2018-09-30 19:24                                    raiders poverty   \n",
       "5  2018-09-30 19:23  believe world gone bonkers need evolve better ...   \n",
       "6  2018-09-30 19:13  even breathing risk one orlando poorest neighb...   \n",
       "7  2018-09-30 19:09  maybe time rethink idea know better people nee...   \n",
       "8  2018-09-30 19:00  volunteer big bros big sisters many american k...   \n",
       "9  2018-09-30 19:00  americas children brief key national indicator...   \n",
       "\n",
       "   Sentiment  \n",
       "0          0  \n",
       "1         -1  \n",
       "2         -1  \n",
       "3         -1  \n",
       "4         -1  \n",
       "5         -1  \n",
       "6         -1  \n",
       "7          0  \n",
       "8         -1  \n",
       "9          1  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset after sentimental analysis\n",
    "newtrain.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert time stamp column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "newtrain['Date'] = pd.to_datetime(newtrain.Date, dayfirst=True)  #Y/M/D default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtrain.to_csv(\"Sentiment_Twitter_Poverty.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DA]",
   "language": "python",
   "name": "conda-env-DA-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
